import time
import json
import random
import csv
import os
from kafka import KafkaProducer
from kafka.errors import NoBrokersAvailable  # TH√äM D√íNG N√ÄY
# C·∫•u h√¨nh t·ª´ m√¥i tr∆∞·ªùng ho·∫∑c m·∫∑c ƒë·ªãnh
BOOTSTRAP_SERVERS = os.getenv('KAFKA_SERVERS', 'localhost:9092')
TOPIC_NAME = os.getenv('KAFKA_TOPIC', 'transactions')
CSV_FILE_PATH = os.getenv('CSV_PATH', '/opt/spark/apps/transactions_source.csv')

def run_producer():
    # Kh·ªüi t·∫°o producer v·ªõi th√™m c√°c tham s·ªë tin c·∫≠y
    producer = None
    while not producer:
        try:
            producer = KafkaProducer(
                bootstrap_servers=BOOTSTRAP_SERVERS.split(','),
                value_serializer=lambda x: json.dumps(x).encode('utf-8'),
                acks='all'
            )
            print("‚úÖ ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng t·ªõi Kafka!")
        except NoBrokersAvailable:
            print("‚ùå Kafka ch∆∞a s·∫µn s√†ng, ƒëang th·ª≠ l·∫°i sau 5 gi√¢y...")
            time.sleep(5)

    print(f"--- üöÄ Producer started. Sending to {TOPIC_NAME} ---")
    
    try:
        if not os.path.exists(CSV_FILE_PATH):
            raise FileNotFoundError(f"Kh√¥ng th·∫•y file t·∫°i {CSV_FILE_PATH}")

        with open(CSV_FILE_PATH, mode='r', encoding='utf-8-sig') as csv_file:
            csv_reader = csv.DictReader(csv_file)
            
            for count, row in enumerate(csv_reader, 1):
                # G·ª≠i d·ªØ li·ªáu
                producer.send(TOPIC_NAME, value=row)
                producer.flush() 
                
                print(f"[{count}] Sent: User {row.get('User')} | Amount: {row.get('Amount')}")
                
                # Delay ng·∫´u nhi√™n
                time.sleep(random.uniform(1, 5))
                
    except Exception as e:
        print(f"‚ùå Error: {e}")
    finally:
        producer.close()
        print("--- üõë Producer closed ---")

if __name__ == '__main__':
    run_producer()